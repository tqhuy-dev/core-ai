{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from ultralytics import YOLO, solutions\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = YOLO('yolo11n.pt')",
   "id": "d61ead5d51136c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def display_objects(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)[0]\n",
    "\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "c8c5948d95fbc8ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def counting_objects_in_regions(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    regions = [(500, 300, 900, 900),(1200, 300, 1600, 900)]\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)[0]\n",
    "        map_count_in_region = {}\n",
    "        for index, region in enumerate(regions):\n",
    "            map_count_in_region[index] = 0\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            # T√≠nh t√¢m c·ªßa bounding box\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            color = (0, 0, 255)\n",
    "            # Ki·ªÉm tra t√¢m n·∫±m trong v√πng ƒë·ªãnh s·∫µn\n",
    "            for index, region in enumerate(regions):\n",
    "                rx1, ry1, rx2, ry2 = region\n",
    "                if rx1 <= cx <= rx2 and ry1 <= cy <= ry2:\n",
    "                    map_count_in_region[index] = map_count_in_region[index] +1\n",
    "                    color = (0, 255, 0)  # xanh l√° n·∫øu n·∫±m trong v√πng\n",
    "\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "         # V·∫Ω v√πng region\n",
    "        for index, region in enumerate(regions):\n",
    "            cv2.rectangle(frame, (region[0], region[1]), (region[2], region[3]), (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Count in region: {map_count_in_region[index]}', (region[0], region[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, 'prompting: Please detect object in my regions', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "883ba346f4dde285",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "counting_objects_in_regions(\"../resources/video.mp4\", \"../resources/counting_object_regions.mp4\")",
   "id": "d6f20b22507e5e22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def counting_objects_throw_line(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)[0]\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            color = (0, 0, 255)\n",
    "            if cy < 300:\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "        cv2.line(frame, (10, 300), (1800, 300), (0, 255, 0), 2)\n",
    "         # V·∫Ω v√πng region\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "2cf19867885062bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "counting_objects_throw_line(\"../resources/video.mp4\", \"../resources/counting_object_line.mp4\")",
   "id": "88c5f783ae9860bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def counting_objects_in_regions_and_crop(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    regions = [(500, 300, 900, 900),(1200, 300, 1600, 900)]\n",
    "    crop_id = 0\n",
    "    cropped_ids = set()\n",
    "    crop_dir = \"crops\"\n",
    "    os.makedirs(crop_dir, exist_ok=True)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")[0]\n",
    "        # results = model(frame)[0]\n",
    "        map_count_in_region = {}\n",
    "        for index, region in enumerate(regions):\n",
    "            map_count_in_region[index] = 0\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            # Tracking ID\n",
    "            if hasattr(box, 'id') and box.id is not None:\n",
    "                track_id = int(box.id[0])\n",
    "            else:\n",
    "                continue  # Skip n·∫øu kh√¥ng c√≥ ID\n",
    "\n",
    "            # T√≠nh t√¢m c·ªßa bounding box\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            color = (0, 0, 255)\n",
    "            # Ki·ªÉm tra t√¢m n·∫±m trong v√πng ƒë·ªãnh s·∫µn\n",
    "            for index, region in enumerate(regions):\n",
    "                rx1, ry1, rx2, ry2 = region\n",
    "                if rx1 <= cx <= rx2 and ry1 <= cy <= ry2:\n",
    "                    map_count_in_region[index] = map_count_in_region[index] +1\n",
    "                    color = (0, 255, 0)  # xanh l√° n·∫øu n·∫±m trong v√πng\n",
    "                          # üëâ CROP v√† L∆ØU object\n",
    "                    if track_id not in cropped_ids:\n",
    "                        obj_crop = frame[y1:y2, x1:x2]\n",
    "                        crop_path = os.path.join(crop_dir, f\"object_{crop_id:04d}_{label}.jpg\")\n",
    "                        cv2.imwrite(crop_path, obj_crop)\n",
    "                        cropped_ids.add(track_id)\n",
    "                        crop_id += 1\n",
    "\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "         # V·∫Ω v√πng region\n",
    "        for index, region in enumerate(regions):\n",
    "            cv2.rectangle(frame, (region[0], region[1]), (region[2], region[3]), (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Count in region: {map_count_in_region[index]}', (region[0], region[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "2117dafdf6ba06ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def counting_objects_in_regions_and_crop_and_blur(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    regions = [(500, 300, 900, 900),(1200, 300, 1600, 900)]\n",
    "    crop_id = 0\n",
    "    cropped_ids = set()\n",
    "    crop_dir = \"crops\"\n",
    "    os.makedirs(crop_dir, exist_ok=True)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")[0]\n",
    "        # results = model(frame)[0]\n",
    "        map_count_in_region = {}\n",
    "        for index, region in enumerate(regions):\n",
    "            map_count_in_region[index] = 0\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            # Tracking ID\n",
    "            if hasattr(box, 'id') and box.id is not None:\n",
    "                track_id = int(box.id[0])\n",
    "            else:\n",
    "                continue  # Skip n·∫øu kh√¥ng c√≥ ID\n",
    "\n",
    "            # T√≠nh t√¢m c·ªßa bounding box\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            color = (0, 0, 255)\n",
    "            # Ki·ªÉm tra t√¢m n·∫±m trong v√πng ƒë·ªãnh s·∫µn\n",
    "            for index, region in enumerate(regions):\n",
    "                rx1, ry1, rx2, ry2 = region\n",
    "                if rx1 <= cx <= rx2 and ry1 <= cy <= ry2:\n",
    "                    map_count_in_region[index] = map_count_in_region[index] +1\n",
    "                    color = (0, 255, 0)  # xanh l√° n·∫øu n·∫±m trong v√πng\n",
    "                          # üëâ CROP v√† L∆ØU object\n",
    "\n",
    "                     # ‚úÖ Blur object trong frame\n",
    "                    object_area = frame[y1:y2, x1:x2]\n",
    "                    blurred = cv2.GaussianBlur(object_area, (35, 35), 30)\n",
    "                    frame[y1:y2, x1:x2] = blurred\n",
    "\n",
    "                    # if track_id not in cropped_ids:\n",
    "                    #     obj_crop = frame[y1:y2, x1:x2]\n",
    "                    #     crop_path = os.path.join(crop_dir, f\"object_{crop_id:04d}_{label}.jpg\")\n",
    "                    #     cv2.imwrite(crop_path, obj_crop)\n",
    "                    #     cropped_ids.add(track_id)\n",
    "                    #     crop_id += 1\n",
    "\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "         # V·∫Ω v√πng region\n",
    "        for index, region in enumerate(regions):\n",
    "            cv2.rectangle(frame, (region[0], region[1]), (region[2], region[3]), (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Count in region: {map_count_in_region[index]}', (region[0], region[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        cv2.putText(frame, 'prompting: Please detect object in my regions and blur it', (10, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "94c7211d7751d601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "counting_objects_in_regions_and_crop_and_blur(\"../resources/video.mp4\", \"../resources/counting_object_regions_blur.mp4\")",
   "id": "f74ff2d250184ce4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_objects_heatmap(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    # B·∫£n ƒë·ªì t√≠ch l≈©y ƒëi·ªÉm n√≥ng\n",
    "    heatmap_accumulator = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    # Kernel ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng lan t·ªèa quanh centroid\n",
    "    kernel = np.zeros((50, 50), np.uint8)\n",
    "    cv2.circle(kernel, (25, 25), 25, 1, -1)\n",
    "    ALPHA = 0.7  # ƒë·ªô trong su·ªët c·ªßa heatmap overlay\n",
    "    DECAY = 0.98  # l√†m m·ªù d·∫ßn heatmap theo th·ªùi gian\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame)[0]\n",
    "\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "             # Ch·ªìng kernel v√†o heatmap t·∫°i v·ªã tr√≠ centroid\n",
    "            top = max(cy - 25, 0)\n",
    "            left = max(cx - 25, 0)\n",
    "            bottom = min(cy + 25, h)\n",
    "            right = min(cx + 25, w)\n",
    "\n",
    "            h_k = bottom - top\n",
    "            w_k = right - left\n",
    "\n",
    "            heatmap_accumulator[top:bottom, left:right] += kernel[:h_k, :w_k]\n",
    "\n",
    "        # L√†m m·ªù heatmap qua th·ªùi gian\n",
    "        heatmap_accumulator *= DECAY\n",
    "\n",
    "        # Normalize v√† chuy·ªÉn sang m√†u\n",
    "        norm_heatmap = cv2.normalize(heatmap_accumulator, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        heatmap_color = cv2.applyColorMap(norm_heatmap.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "\n",
    "         # Overlay heatmap l√™n frame g·ªëc\n",
    "        blended = cv2.addWeighted(frame, 1 - ALPHA, heatmap_color, ALPHA, 0)\n",
    "        out.write(blended)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "7820aa31f6e4d5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# display_objects(\"../resources/video.mp4\", \"output_video.mp4\")\n",
    "counting_objects_in_regions(\"../resources/video.mp4\", \"../resources/counting_object_regions.mp4\")"
   ],
   "id": "466388046d980243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def object_queue_counter(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "    counter = 0\n",
    "    box_id_dict = {}\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")[0]\n",
    "\n",
    "\n",
    "        for box in results.boxes:\n",
    "\n",
    "            # Tracking ID\n",
    "            if hasattr(box, 'id') and box.id is not None:\n",
    "                track_id = int(box.id[0])\n",
    "            else:\n",
    "                continue  # Skip n·∫øu kh√¥ng c√≥ ID\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "            if label != \"person\" or conf < 0.5:\n",
    "                continue\n",
    "            if track_id not in box_id_dict:\n",
    "                box_id_dict[track_id] = counter\n",
    "                counter += 1\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'#{box_id_dict[track_id]} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "e2a7831922df3d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "object_queue_counter('../resources/queue_video.mp4', '../resources/queue_video_output.mp4')",
   "id": "deef909e347479bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:30:57.714253Z",
     "start_time": "2025-06-03T11:30:57.711818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def point_in_polygon(x, y, polygon):\n",
    "    return cv2.pointPolygonTest(np.array(polygon, dtype=np.int32), (x, y), False) >= 0"
   ],
   "id": "ccb5a99e996c5bbb",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:40:09.061565Z",
     "start_time": "2025-06-03T11:40:09.051519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "polygons = [\n",
    "    [(180, 130), (0, 400), (200, 400),(310, 130)],\n",
    "    [(310, 130), (180, 470), (400, 470),(480, 130)],\n",
    "     [(490, 130), (400, 470), (630, 470),(650, 130)],\n",
    "    [(650, 130), (640, 470), (850, 470),(810, 130)],\n",
    "    [(810, 130), (860, 470), (1100, 470),(960, 130)],\n",
    "    [(970, 130), (1100, 470), (1300, 470),(1130, 130)],\n",
    "]\n",
    "\n",
    "\n",
    "def parking_slot_detect(video_path, output_video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "        results = model(frame)[0]\n",
    "\n",
    "        index_park_dict = {}\n",
    "\n",
    "\n",
    "        for box in results.boxes:\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            cx = (x1 + x2) // 2\n",
    "            cy = (y1 + y2) // 2\n",
    "\n",
    "            cls = int(box.cls[0])\n",
    "            label = model.names[cls]\n",
    "            conf = box.conf[0]\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "            for index, polygon in enumerate(polygons):\n",
    "                if point_in_polygon(cx, cy, polygon):\n",
    "                    index_park_dict[index] = True\n",
    "\n",
    "        for index , polygon in enumerate(polygons):\n",
    "            color = (0, 255, 0) if index in index_park_dict else (0, 0, 255)\n",
    "            pts_np = np.array(polygon, dtype=np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(frame, [pts_np], isClosed=True, color=color, thickness=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "9398bea98c4a7dc9",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:24:51.572991Z",
     "start_time": "2025-06-03T11:24:51.561538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# img = cv2.imread(\"../resources/parking_slot_mask.jpg\")\n",
    "#\n",
    "#\n",
    "# Danh s√°ch polygon: m·ªói c√°i l√† list c√°c (x, y)\n",
    "# polygons = [\n",
    "#     [(180, 130), (0, 400), (200, 400),(310, 130)],\n",
    "#     [(310, 130), (180, 470), (400, 470),(480, 130)],\n",
    "#      [(490, 130), (400, 470), (630, 470),(650, 130)],\n",
    "#     [(650, 130), (640, 470), (850, 470),(810, 130)],\n",
    "#     [(810, 130), (860, 470), (1100, 470),(960, 130)],\n",
    "#     [(970, 130), (1100, 470), (1300, 470),(1130, 130)],\n",
    "# ]\n",
    "#\n",
    "# V·∫Ω t·ª´ng polygon\n",
    "# for pts in polygons:\n",
    "#     pts_np = np.array(pts, dtype=np.int32).reshape((-1, 1, 2))\n",
    "#     cv2.polylines(img, [pts_np], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# # (Tu·ª≥ ch·ªçn) v·∫Ω ID v√πng\n",
    "# for i, pts in enumerate(polygons):\n",
    "#     cx = int(np.mean([p[0] for p in pts]))\n",
    "#     cy = int(np.mean([p[1] for p in pts]))\n",
    "#     cv2.putText(img, f\"Region {i+1}\", (cx - 20, cy),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "# L∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "# cv2.imwrite(\"../resources/parking_slot_mask_output.jpg\", img)"
   ],
   "id": "f0331c0259771df3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:06:36.240909Z",
     "start_time": "2025-06-03T11:06:36.182770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# video_path = \"../resources/parking_slot.mp4\"\n",
    "#\n",
    "# # M·ªü video\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "#\n",
    "# # L·∫•y frame ƒë·∫ßu ti√™n (frame s·ªë 0)\n",
    "# frame_number = 0\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "#\n",
    "# # ƒê·ªçc frame\n",
    "# ret, frame = cap.read()\n",
    "#\n",
    "# if ret:\n",
    "#     # L∆∞u frame th√†nh ·∫£nh\n",
    "#     cv2.imwrite(\"../resources/parking_slot_mask.jpg\", frame)\n",
    "#     print(\"ƒê√£ l∆∞u frame th√†nh c√¥ng!\")\n",
    "# else:\n",
    "#     print(\"Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ video.\")\n",
    "#\n",
    "# cap.release()"
   ],
   "id": "5248f86454f9e3e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u frame th√†nh c√¥ng!\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T11:40:21.460557Z",
     "start_time": "2025-06-03T11:40:13.332562Z"
    }
   },
   "cell_type": "code",
   "source": "parking_slot_detect('../resources/parking_slot.mp4' , '../resources/parking_slot_output.mp4')",
   "id": "a6fcb60af3eebf12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 cars, 47.8ms\n",
      "Speed: 4.9ms preprocess, 47.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 cell phone, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 35.5ms\n",
      "Speed: 1.3ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 cell phone, 55.0ms\n",
      "Speed: 1.3ms preprocess, 55.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 cell phone, 36.6ms\n",
      "Speed: 1.3ms preprocess, 36.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 cell phone, 37.7ms\n",
      "Speed: 1.3ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 34.2ms\n",
      "Speed: 1.1ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 35.7ms\n",
      "Speed: 1.0ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 34.8ms\n",
      "Speed: 1.0ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 32.4ms\n",
      "Speed: 1.4ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 32.6ms\n",
      "Speed: 1.1ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 33.8ms\n",
      "Speed: 1.1ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 32.3ms\n",
      "Speed: 1.2ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 31.3ms\n",
      "Speed: 1.2ms preprocess, 31.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.4ms\n",
      "Speed: 1.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.9ms\n",
      "Speed: 0.9ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.0ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.1ms\n",
      "Speed: 1.1ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 35.3ms\n",
      "Speed: 1.1ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.3ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.8ms\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.1ms\n",
      "Speed: 1.1ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.3ms\n",
      "Speed: 1.1ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 33.0ms\n",
      "Speed: 1.1ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 31.6ms\n",
      "Speed: 1.1ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.0ms\n",
      "Speed: 1.1ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 33.0ms\n",
      "Speed: 1.2ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.2ms\n",
      "Speed: 1.2ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 31.7ms\n",
      "Speed: 1.2ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 31.4ms\n",
      "Speed: 1.2ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 34.5ms\n",
      "Speed: 1.0ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 34.9ms\n",
      "Speed: 1.1ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.4ms\n",
      "Speed: 1.1ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 31.9ms\n",
      "Speed: 1.3ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.1ms\n",
      "Speed: 1.1ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 33.0ms\n",
      "Speed: 1.4ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.6ms\n",
      "Speed: 1.1ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.5ms\n",
      "Speed: 1.2ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.4ms\n",
      "Speed: 1.1ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.3ms\n",
      "Speed: 1.0ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 31.6ms\n",
      "Speed: 1.1ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 33.0ms\n",
      "Speed: 1.1ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 31.3ms\n",
      "Speed: 1.1ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 38.9ms\n",
      "Speed: 1.1ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 32.3ms\n",
      "Speed: 1.1ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 3 trucks, 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 31.9ms\n",
      "Speed: 1.1ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.1ms\n",
      "Speed: 1.1ms preprocess, 32.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.7ms\n",
      "Speed: 1.2ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 31.2ms\n",
      "Speed: 1.1ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.3ms\n",
      "Speed: 1.1ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.9ms\n",
      "Speed: 1.1ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.2ms\n",
      "Speed: 1.3ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.2ms\n",
      "Speed: 1.2ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.0ms\n",
      "Speed: 1.2ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.2ms\n",
      "Speed: 1.1ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.1ms\n",
      "Speed: 1.4ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.7ms\n",
      "Speed: 1.3ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.0ms\n",
      "Speed: 1.1ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 33.2ms\n",
      "Speed: 1.2ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.8ms\n",
      "Speed: 1.0ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 32.9ms\n",
      "Speed: 1.1ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.6ms\n",
      "Speed: 1.1ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.6ms\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.2ms\n",
      "Speed: 1.0ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.3ms\n",
      "Speed: 1.2ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.4ms\n",
      "Speed: 1.0ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.4ms\n",
      "Speed: 1.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.0ms\n",
      "Speed: 1.1ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.1ms\n",
      "Speed: 1.1ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.2ms\n",
      "Speed: 1.1ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.2ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.2ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 31.7ms\n",
      "Speed: 1.1ms preprocess, 31.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.6ms\n",
      "Speed: 1.1ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.9ms\n",
      "Speed: 1.2ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 34.0ms\n",
      "Speed: 1.2ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.9ms\n",
      "Speed: 1.3ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.4ms\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.0ms\n",
      "Speed: 1.2ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.7ms\n",
      "Speed: 1.3ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.7ms\n",
      "Speed: 1.3ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.4ms\n",
      "Speed: 1.2ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.3ms\n",
      "Speed: 1.1ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.9ms\n",
      "Speed: 1.2ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.2ms\n",
      "Speed: 1.1ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.7ms\n",
      "Speed: 1.2ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 35.8ms\n",
      "Speed: 1.5ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.9ms\n",
      "Speed: 1.0ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.1ms\n",
      "Speed: 1.4ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.6ms\n",
      "Speed: 1.4ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.2ms\n",
      "Speed: 1.2ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.9ms\n",
      "Speed: 1.3ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.1ms\n",
      "Speed: 1.3ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.8ms\n",
      "Speed: 1.3ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.3ms\n",
      "Speed: 1.3ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.5ms\n",
      "Speed: 1.6ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.1ms\n",
      "Speed: 1.2ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 31.5ms\n",
      "Speed: 1.2ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.6ms\n",
      "Speed: 2.2ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.2ms\n",
      "Speed: 1.3ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.6ms\n",
      "Speed: 1.2ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 32.1ms\n",
      "Speed: 1.6ms preprocess, 32.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 31.9ms\n",
      "Speed: 1.4ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 32.9ms\n",
      "Speed: 1.4ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 34.2ms\n",
      "Speed: 1.1ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 32.7ms\n",
      "Speed: 1.1ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 32.9ms\n",
      "Speed: 1.0ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 35.1ms\n",
      "Speed: 1.6ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 33.4ms\n",
      "Speed: 1.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 33.4ms\n",
      "Speed: 1.3ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 37.0ms\n",
      "Speed: 1.3ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 33.6ms\n",
      "Speed: 1.0ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 32.9ms\n",
      "Speed: 1.3ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 33.2ms\n",
      "Speed: 1.2ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 34.1ms\n",
      "Speed: 1.2ms preprocess, 34.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 32.8ms\n",
      "Speed: 1.3ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 35.3ms\n",
      "Speed: 1.3ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 33.0ms\n",
      "Speed: 1.4ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.3ms\n",
      "Speed: 1.2ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.2ms\n",
      "Speed: 1.4ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.2ms\n",
      "Speed: 1.1ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.6ms\n",
      "Speed: 1.2ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.3ms\n",
      "Speed: 1.2ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.0ms\n",
      "Speed: 1.2ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 33.5ms\n",
      "Speed: 1.2ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 34.9ms\n",
      "Speed: 1.3ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 33.9ms\n",
      "Speed: 1.0ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 32.2ms\n",
      "Speed: 1.0ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.5ms\n",
      "Speed: 1.1ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.8ms\n",
      "Speed: 1.3ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.7ms\n",
      "Speed: 1.1ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.4ms\n",
      "Speed: 1.2ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 32.8ms\n",
      "Speed: 1.1ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.3ms\n",
      "Speed: 0.9ms preprocess, 33.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.7ms\n",
      "Speed: 1.0ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 35.4ms\n",
      "Speed: 1.0ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 34.0ms\n",
      "Speed: 1.1ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.2ms\n",
      "Speed: 1.1ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.7ms\n",
      "Speed: 1.1ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.2ms\n",
      "Speed: 1.1ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 34.1ms\n",
      "Speed: 1.1ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 truck, 33.6ms\n",
      "Speed: 1.1ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 33.5ms\n",
      "Speed: 1.1ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "execution_count": 196
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
